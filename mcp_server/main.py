import os
import base64
import asyncio
from typing import Any, Sequence
from datetime import datetime
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
import uvicorn
from mcp import McpError, Tool
from mcp.server import Server
from mcp.server.stdio import stdio_server
from mcp.types import TextContent
from pydantic import BaseModel
from dotenv import load_dotenv
from azure.ai.projects import AIProjectClient
from azure.identity import DefaultAzureCredential, ClientSecretCredential

# Charger les variables d'environnement
load_dotenv()

# Configuration Azure AI Foundry


def get_azure_credential():
    try:
        credential = DefaultAzureCredential()
        return credential
    except Exception:
        # Essayer de lire les secrets depuis les fichiers Docker secrets
        def read_secret(name):
            try:
                with open(f'/run/secrets/{name}', 'r') as f:
                    return f.read().strip()
            except FileNotFoundError:
                return os.getenv(name.upper().replace('-', '_'))

        tenant_id = read_secret(
            'azure-tenant-id') or os.getenv("AZURE_TENANT_ID")
        client_id = read_secret(
            'azure-client-id') or os.getenv("AZURE_CLIENT_ID")
        b64_secret = os.getenv("AZURE_CLIENT_SECRET_B64")
        client_secret = read_secret(
            'azure-client-secret') or base64.b64decode(b64_secret).decode("utf-8")

        if tenant_id and client_id and client_secret:
            return ClientSecretCredential(
                tenant_id=tenant_id,
                client_id=client_id,
                client_secret=client_secret
            )
        else:
            raise Exception("Variables d'environnement ou secrets manquants")

# Mod√®les Pydantic pour FastAPI


class ToolCallParams(BaseModel):
    name: str
    arguments: dict


class ToolCallRequest(BaseModel):
    method: str
    params: ToolCallParams


class TextContentResponse(BaseModel):
    type: str = "text"
    text: str


class ToolResponse(BaseModel):
    content: list[TextContentResponse]


class HealthResponse(BaseModel):
    status: str
    timestamp: str


# Cr√©er l'application FastAPI
app = FastAPI(
    title="Azure AI Foundry MCP Server",
    description="Serveur MCP pour ex√©cuter du code et analyser des donn√©es via Azure AI Foundry",
    version="1.0.0"
)

# Cr√©er le serveur MCP
mcp_server = Server("azure-ai-foundry")


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Endpoint de v√©rification de sant√©"""
    return HealthResponse(
        status="healthy",
        timestamp=datetime.now().isoformat()
    )


@app.get("/mcp/tools")
async def list_tools():
    """Liste les outils disponibles"""
    return {
        "tools": [
            {
                "name": "execute_code",
                "description": "Ex√©cute du code Python via Azure AI Foundry Code Interpreter",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "message": {
                            "type": "string",
                            "description": "Le code Python √† ex√©cuter ou la t√¢che √† accomplir"
                        }
                    },
                    "required": ["message"]
                }
            },
            {
                "name": "analyze_data",
                "description": "Analyse des donn√©es avec Azure AI Foundry",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "message": {
                            "type": "string",
                            "description": "La question d'analyse ou la t√¢che d'analyse de donn√©es"
                        },
                        "data_context": {
                            "type": "string",
                            "description": "Contexte des donn√©es ou format des donn√©es √† analyser"
                        }
                    },
                    "required": ["message"]
                }
            }
        ]
    }


async def call_tool_logic(tool_name: str, arguments: dict) -> str:
    """Logique de traitement des outils extraite pour utilisation dans Azure Functions"""
    try:
        # Configuration Azure
        credential = get_azure_credential()
        endpoint = os.getenv("AZURE_AI_FOUNDRY_ENDPOINT")
        agent_id = os.getenv("AZURE_AI_AGENT_ID")

        project = AIProjectClient(
            credential=credential,
            endpoint=endpoint
        )

        if tool_name == "execute_code":
            message = arguments.get("message", "")
            if not message:
                raise Exception("Message requis")

            # Cr√©er un thread
            thread = project.agents.threads.create()

            # Envoyer le message
            project.agents.messages.create(
                thread_id=thread.id,
                role="user",
                content=f"Ex√©cute ce code Python: {message}"
            )

            # Ex√©cuter
            run = project.agents.runs.create_and_process(
                thread_id=thread.id,
                agent_id=agent_id
            )

            if run.status == "failed":
                return f"Erreur d'ex√©cution: {run.last_error}"

            # R√©cup√©rer la r√©ponse
            messages = project.agents.messages.list(thread_id=thread.id)

            for msg in messages:
                if msg.role == "assistant" and msg.text_messages:
                    response = msg.text_messages[-1].text.value
                    return f"‚úÖ Code ex√©cut√© avec succ√®s:\n\n{response}"

            return "‚úÖ Code ex√©cut√© mais aucune r√©ponse re√ßue"

        elif tool_name == "analyze_data":
            message = arguments.get("message", "")
            data_context = arguments.get("data_context", "")

            if not message:
                raise Exception("Message requis")

            # Cr√©er un thread
            thread = project.agents.threads.create()

            # Construire le message d'analyse
            analysis_prompt = f"""
            Analyse les donn√©es suivantes:
            Context: {data_context}
            Question: {message}
            
            Fournis une analyse d√©taill√©e avec du code Python si n√©cessaire.
            """

            # Envoyer le message
            project.agents.messages.create(
                thread_id=thread.id,
                role="user",
                content=analysis_prompt
            )

            # Ex√©cuter
            run = project.agents.runs.create_and_process(
                thread_id=thread.id,
                agent_id=agent_id
            )

            if run.status == "failed":
                return f"Erreur d'analyse: {run.last_error}"

            # R√©cup√©rer la r√©ponse
            messages = project.agents.messages.list(thread_id=thread.id)

            for msg in messages:
                if msg.role == "assistant" and msg.text_messages:
                    response = msg.text_messages[-1].text.value
                    return f"üìä Analyse termin√©e:\n\n{response}"

            return "üìä Analyse termin√©e mais aucune r√©ponse re√ßue"

        else:
            raise Exception(f"Outil inconnu: {tool_name}")

    except Exception as e:
        raise Exception(f"Erreur: {str(e)}")


@app.post("/mcp/call", response_model=ToolResponse)
async def call_tool(request: ToolCallRequest):
    """Appelle un outil sp√©cifique"""

    if request.method != "tools/call":
        raise HTTPException(status_code=400, detail="M√©thode non support√©e")

    tool_name = request.params.name
    arguments = request.params.arguments

    try:
        result = await call_tool_logic(tool_name, arguments)
        return ToolResponse(content=[
            TextContentResponse(text=result)
        ])
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    # Lancer le serveur FastAPI
    uvicorn.run(app, host="0.0.0.0", port=8000)
